{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f0666b6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/komangwikananda/miniconda3/envs/imageclassification/lib/python3.13/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from utils.datamodule import DataModule\n",
    "import yaml\n",
    "from utils.engine import train, test, predict_single_img, _save_train_plot\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from PIL import ImageFile\n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a48b930b",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"dataset.yaml\", 'r') as f:\n",
    "    dataset_cfg = yaml.safe_load(f)\n",
    "\n",
    "with open(\"train.yaml\", 'r') as f:\n",
    "    train_cfg = yaml.safe_load(f)\n",
    "\n",
    "\n",
    "dm = DataModule(dataset_cfg)\n",
    "dm.setup(processed=True, skip_large=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3343ac6",
   "metadata": {},
   "outputs": [],
   "source": [
    "model, curves = train(dm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bb7bb06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input shape:  (64, 3, 128, 128)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/komangwikananda/miniconda3/envs/imageclassification/lib/python3.13/site-packages/PIL/Image.py:1047: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "------------------------------------- Calculate Flops Results -------------------------------------\n",
      "Notations:\n",
      "number of parameters (Params), number of multiply-accumulate operations(MACs),\n",
      "number of floating-point operations (FLOPs), floating-point operations per second (FLOPS),\n",
      "fwd FLOPs (model forward propagation FLOPs), bwd FLOPs (model backward propagation FLOPs),\n",
      "default model backpropagation takes 2.00 times as much computation as forward propagation.\n",
      "\n",
      "Total Training Params:                                                  116.23 K\n",
      "fwd MACs:                                                               20.5692 GMACs\n",
      "fwd FLOPs:                                                              41.4501 GFLOPS\n",
      "fwd+bwd MACs:                                                           61.7075 GMACs\n",
      "fwd+bwd FLOPs:                                                          124.35 GFLOPS\n",
      "\n",
      "-------------------------------- Detailed Calculated FLOPs Results --------------------------------\n",
      "Each module caculated is listed after its name in the following order: \n",
      "params, percentage of total params, MACs, percentage of total MACs, FLOPS, percentage of total FLOPs\n",
      "\n",
      "Note: 1. A module can have torch.nn.module or torch.nn.functional to compute logits (e.g. CrossEntropyLoss). \n",
      " They are not counted as submodules in calflops and not to be printed out. However they make up the difference between a parent's MACs and the sum of its submodules'.\n",
      "2. Number of floating-point operations is a theoretical estimation, thus FLOPS computed using that could be larger than the maximum system throughput.\n",
      "\n",
      "TimmClassifier(\n",
      "  116.23 K = 100% Params, 20.57 GMACs = 100% MACs, 41.45 GFLOPS = 100% FLOPs\n",
      "  (backbone): SwiftFormer(\n",
      "    0 = 0% Params, 20.56 GMACs = 99.964% MACs, 41.44 GFLOPS = 99.9636% FLOPs\n",
      "    (stem): Sequential(\n",
      "      0 = 0% Params, 849.35 MMACs = 4.1292% MACs, 1.74 GFLOPS = 4.1892% FLOPs\n",
      "      (0): Conv2d(0 = 0% Params, 169.87 MMACs = 0.8258% MACs, 346.03 MFLOPS = 0.8348% FLOPs, 3, 24, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "      (1): BatchNorm2d(0 = 0% Params, 0 MACs = 0% MACs, 12.58 MFLOPS = 0.0304% FLOPs, 24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): ReLU(0 = 0% Params, 0 MACs = 0% MACs, 6.29 MFLOPS = 0.0152% FLOPs)\n",
      "      (3): Conv2d(0 = 0% Params, 679.48 MMACs = 3.3034% MACs, 1.36 GFLOPS = 3.2861% FLOPs, 24, 48, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "      (4): BatchNorm2d(0 = 0% Params, 0 MACs = 0% MACs, 6.29 MFLOPS = 0.0152% FLOPs, 48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (5): ReLU(0 = 0% Params, 0 MACs = 0% MACs, 3.15 MFLOPS = 0.0076% FLOPs)\n",
      "    )\n",
      "    (stages): Sequential(\n",
      "      0 = 0% Params, 19.71 GMACs = 95.8348% MACs, 39.7 GFLOPS = 95.7733% FLOPs\n",
      "      (0): Stage(\n",
      "        0 = 0% Params, 4.61 GMACs = 22.4354% MACs, 9.36 GFLOPS = 22.5779% FLOPs\n",
      "        (downsample): Identity(0 = 0% Params, 0 MACs = 0% MACs, 0 FLOPS = 0% FLOPs)\n",
      "        (blocks): Sequential(\n",
      "          0 = 0% Params, 4.61 GMACs = 22.4354% MACs, 9.36 GFLOPS = 22.5779% FLOPs\n",
      "          (0): ConvEncoder(\n",
      "            0 = 0% Params, 1.24 GMACs = 6.0103% MACs, 2.51 GFLOPS = 6.0562% FLOPs\n",
      "            (dwconv): Conv2d(0 = 0% Params, 28.31 MMACs = 0.1376% MACs, 59.77 MFLOPS = 0.1442% FLOPs, 48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=48)\n",
      "            (norm): BatchNorm2d(0 = 0% Params, 0 MACs = 0% MACs, 6.29 MFLOPS = 0.0152% FLOPs, 48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (pwconv1): Conv2d(0 = 0% Params, 603.98 MMACs = 2.9363% MACs, 1.22 GFLOPS = 2.9446% FLOPs, 48, 192, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (act): GELU(0 = 0% Params, 0 MACs = 0% MACs, 12.58 MFLOPS = 0.0304% FLOPs, approximate='none')\n",
      "            (pwconv2): Conv2d(0 = 0% Params, 603.98 MMACs = 2.9363% MACs, 1.21 GFLOPS = 2.9218% FLOPs, 192, 48, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (drop_path): Identity(0 = 0% Params, 0 MACs = 0% MACs, 0 FLOPS = 0% FLOPs)\n",
      "            (layer_scale): LayerScale2d(0 = 0% Params, 0 MACs = 0% MACs, 0 FLOPS = 0% FLOPs)\n",
      "          )\n",
      "          (1): ConvEncoder(\n",
      "            0 = 0% Params, 1.24 GMACs = 6.0103% MACs, 2.51 GFLOPS = 6.0562% FLOPs\n",
      "            (dwconv): Conv2d(0 = 0% Params, 28.31 MMACs = 0.1376% MACs, 59.77 MFLOPS = 0.1442% FLOPs, 48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=48)\n",
      "            (norm): BatchNorm2d(0 = 0% Params, 0 MACs = 0% MACs, 6.29 MFLOPS = 0.0152% FLOPs, 48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (pwconv1): Conv2d(0 = 0% Params, 603.98 MMACs = 2.9363% MACs, 1.22 GFLOPS = 2.9446% FLOPs, 48, 192, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (act): GELU(0 = 0% Params, 0 MACs = 0% MACs, 12.58 MFLOPS = 0.0304% FLOPs, approximate='none')\n",
      "            (pwconv2): Conv2d(0 = 0% Params, 603.98 MMACs = 2.9363% MACs, 1.21 GFLOPS = 2.9218% FLOPs, 192, 48, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (drop_path): Identity(0 = 0% Params, 0 MACs = 0% MACs, 0 FLOPS = 0% FLOPs)\n",
      "            (layer_scale): LayerScale2d(0 = 0% Params, 0 MACs = 0% MACs, 0 FLOPS = 0% FLOPs)\n",
      "          )\n",
      "          (2): Block(\n",
      "            0 = 0% Params, 2.14 GMACs = 10.4148% MACs, 4.34 GFLOPS = 10.4655% FLOPs\n",
      "            (local_representation): LocalRepresentation(\n",
      "              0 = 0% Params, 330.3 MMACs = 1.6058% MACs, 679.48 MFLOPS = 1.6393% FLOPs\n",
      "              (dwconv): Conv2d(0 = 0% Params, 28.31 MMACs = 0.1376% MACs, 59.77 MFLOPS = 0.1442% FLOPs, 48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=48)\n",
      "              (norm): BatchNorm2d(0 = 0% Params, 0 MACs = 0% MACs, 6.29 MFLOPS = 0.0152% FLOPs, 48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "              (pwconv1): Conv2d(0 = 0% Params, 150.99 MMACs = 0.7341% MACs, 305.14 MFLOPS = 0.7362% FLOPs, 48, 48, kernel_size=(1, 1), stride=(1, 1))\n",
      "              (act): GELU(0 = 0% Params, 0 MACs = 0% MACs, 3.15 MFLOPS = 0.0076% FLOPs, approximate='none')\n",
      "              (pwconv2): Conv2d(0 = 0% Params, 150.99 MMACs = 0.7341% MACs, 305.14 MFLOPS = 0.7362% FLOPs, 48, 48, kernel_size=(1, 1), stride=(1, 1))\n",
      "              (drop_path): Identity(0 = 0% Params, 0 MACs = 0% MACs, 0 FLOPS = 0% FLOPs)\n",
      "              (layer_scale): LayerScale2d(0 = 0% Params, 0 MACs = 0% MACs, 0 FLOPS = 0% FLOPs)\n",
      "            )\n",
      "            (attn): EfficientAdditiveAttention(\n",
      "              0 = 0% Params, 603.98 MMACs = 2.9363% MACs, 1.21 GFLOPS = 2.9143% FLOPs\n",
      "              (to_query): Linear(0 = 0% Params, 150.99 MMACs = 0.7341% MACs, 301.99 MFLOPS = 0.7286% FLOPs, in_features=48, out_features=48, bias=True)\n",
      "              (to_key): Linear(0 = 0% Params, 150.99 MMACs = 0.7341% MACs, 301.99 MFLOPS = 0.7286% FLOPs, in_features=48, out_features=48, bias=True)\n",
      "              (proj): Linear(0 = 0% Params, 150.99 MMACs = 0.7341% MACs, 301.99 MFLOPS = 0.7286% FLOPs, in_features=48, out_features=48, bias=True)\n",
      "              (final): Linear(0 = 0% Params, 150.99 MMACs = 0.7341% MACs, 301.99 MFLOPS = 0.7286% FLOPs, in_features=48, out_features=48, bias=True)\n",
      "            )\n",
      "            (linear): Mlp(\n",
      "              0 = 0% Params, 1.21 GMACs = 5.8727% MACs, 2.45 GFLOPS = 5.912% FLOPs\n",
      "              (norm1): BatchNorm2d(0 = 0% Params, 0 MACs = 0% MACs, 6.29 MFLOPS = 0.0152% FLOPs, 48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "              (fc1): Conv2d(0 = 0% Params, 603.98 MMACs = 2.9363% MACs, 1.22 GFLOPS = 2.9446% FLOPs, 48, 192, kernel_size=(1, 1), stride=(1, 1))\n",
      "              (act): GELU(0 = 0% Params, 0 MACs = 0% MACs, 12.58 MFLOPS = 0.0304% FLOPs, approximate='none')\n",
      "              (fc2): Conv2d(0 = 0% Params, 603.98 MMACs = 2.9363% MACs, 1.21 GFLOPS = 2.9218% FLOPs, 192, 48, kernel_size=(1, 1), stride=(1, 1))\n",
      "              (drop): Dropout(0 = 0% Params, 0 MACs = 0% MACs, 0 FLOPS = 0% FLOPs, p=0.0, inplace=False)\n",
      "            )\n",
      "            (drop_path): Identity(0 = 0% Params, 0 MACs = 0% MACs, 0 FLOPS = 0% FLOPs)\n",
      "            (layer_scale_1): LayerScale2d(0 = 0% Params, 0 MACs = 0% MACs, 0 FLOPS = 0% FLOPs)\n",
      "            (layer_scale_2): LayerScale2d(0 = 0% Params, 0 MACs = 0% MACs, 0 FLOPS = 0% FLOPs)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (1): Stage(\n",
      "        0 = 0% Params, 2.49 GMACs = 12.1277% MACs, 5.04 GFLOPS = 12.1478% FLOPs\n",
      "        (downsample): Embedding(\n",
      "          0 = 0% Params, 452.98 MMACs = 2.2023% MACs, 909.12 MFLOPS = 2.1933% FLOPs\n",
      "          (proj): Conv2d(0 = 0% Params, 452.98 MMACs = 2.2023% MACs, 907.02 MFLOPS = 2.1882% FLOPs, 48, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "          (norm): BatchNorm2d(0 = 0% Params, 0 MACs = 0% MACs, 2.1 MFLOPS = 0.0051% FLOPs, 64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "        (blocks): Sequential(\n",
      "          0 = 0% Params, 2.04 GMACs = 9.9254% MACs, 4.13 GFLOPS = 9.9545% FLOPs\n",
      "          (0): ConvEncoder(\n",
      "            0 = 0% Params, 546.31 MMACs = 2.656% MACs, 1.11 GFLOPS = 2.6663% FLOPs\n",
      "            (dwconv): Conv2d(0 = 0% Params, 9.44 MMACs = 0.0459% MACs, 19.92 MFLOPS = 0.0481% FLOPs, 64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64)\n",
      "            (norm): BatchNorm2d(0 = 0% Params, 0 MACs = 0% MACs, 2.1 MFLOPS = 0.0051% FLOPs, 64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (pwconv1): Conv2d(0 = 0% Params, 268.44 MMACs = 1.305% MACs, 541.07 MFLOPS = 1.3053% FLOPs, 64, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (act): GELU(0 = 0% Params, 0 MACs = 0% MACs, 4.19 MFLOPS = 0.0101% FLOPs, approximate='none')\n",
      "            (pwconv2): Conv2d(0 = 0% Params, 268.44 MMACs = 1.305% MACs, 537.92 MFLOPS = 1.2978% FLOPs, 256, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (drop_path): Identity(0 = 0% Params, 0 MACs = 0% MACs, 0 FLOPS = 0% FLOPs)\n",
      "            (layer_scale): LayerScale2d(0 = 0% Params, 0 MACs = 0% MACs, 0 FLOPS = 0% FLOPs)\n",
      "          )\n",
      "          (1): ConvEncoder(\n",
      "            0 = 0% Params, 546.31 MMACs = 2.656% MACs, 1.11 GFLOPS = 2.6663% FLOPs\n",
      "            (dwconv): Conv2d(0 = 0% Params, 9.44 MMACs = 0.0459% MACs, 19.92 MFLOPS = 0.0481% FLOPs, 64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64)\n",
      "            (norm): BatchNorm2d(0 = 0% Params, 0 MACs = 0% MACs, 2.1 MFLOPS = 0.0051% FLOPs, 64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (pwconv1): Conv2d(0 = 0% Params, 268.44 MMACs = 1.305% MACs, 541.07 MFLOPS = 1.3053% FLOPs, 64, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (act): GELU(0 = 0% Params, 0 MACs = 0% MACs, 4.19 MFLOPS = 0.0101% FLOPs, approximate='none')\n",
      "            (pwconv2): Conv2d(0 = 0% Params, 268.44 MMACs = 1.305% MACs, 537.92 MFLOPS = 1.2978% FLOPs, 256, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (drop_path): Identity(0 = 0% Params, 0 MACs = 0% MACs, 0 FLOPS = 0% FLOPs)\n",
      "            (layer_scale): LayerScale2d(0 = 0% Params, 0 MACs = 0% MACs, 0 FLOPS = 0% FLOPs)\n",
      "          )\n",
      "          (2): Block(\n",
      "            0 = 0% Params, 948.96 MMACs = 4.6135% MACs, 1.92 GFLOPS = 4.6218% FLOPs\n",
      "            (local_representation): LocalRepresentation(\n",
      "              0 = 0% Params, 143.65 MMACs = 0.6984% MACs, 293.6 MFLOPS = 0.7083% FLOPs\n",
      "              (dwconv): Conv2d(0 = 0% Params, 9.44 MMACs = 0.0459% MACs, 19.92 MFLOPS = 0.0481% FLOPs, 64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64)\n",
      "              (norm): BatchNorm2d(0 = 0% Params, 0 MACs = 0% MACs, 2.1 MFLOPS = 0.0051% FLOPs, 64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "              (pwconv1): Conv2d(0 = 0% Params, 67.11 MMACs = 0.3263% MACs, 135.27 MFLOPS = 0.3263% FLOPs, 64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "              (act): GELU(0 = 0% Params, 0 MACs = 0% MACs, 1.05 MFLOPS = 0.0025% FLOPs, approximate='none')\n",
      "              (pwconv2): Conv2d(0 = 0% Params, 67.11 MMACs = 0.3263% MACs, 135.27 MFLOPS = 0.3263% FLOPs, 64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "              (drop_path): Identity(0 = 0% Params, 0 MACs = 0% MACs, 0 FLOPS = 0% FLOPs)\n",
      "              (layer_scale): LayerScale2d(0 = 0% Params, 0 MACs = 0% MACs, 0 FLOPS = 0% FLOPs)\n",
      "            )\n",
      "            (attn): EfficientAdditiveAttention(\n",
      "              0 = 0% Params, 268.44 MMACs = 1.305% MACs, 536.87 MFLOPS = 1.2952% FLOPs\n",
      "              (to_query): Linear(0 = 0% Params, 67.11 MMACs = 0.3263% MACs, 134.22 MFLOPS = 0.3238% FLOPs, in_features=64, out_features=64, bias=True)\n",
      "              (to_key): Linear(0 = 0% Params, 67.11 MMACs = 0.3263% MACs, 134.22 MFLOPS = 0.3238% FLOPs, in_features=64, out_features=64, bias=True)\n",
      "              (proj): Linear(0 = 0% Params, 67.11 MMACs = 0.3263% MACs, 134.22 MFLOPS = 0.3238% FLOPs, in_features=64, out_features=64, bias=True)\n",
      "              (final): Linear(0 = 0% Params, 67.11 MMACs = 0.3263% MACs, 134.22 MFLOPS = 0.3238% FLOPs, in_features=64, out_features=64, bias=True)\n",
      "            )\n",
      "            (linear): Mlp(\n",
      "              0 = 0% Params, 536.87 MMACs = 2.6101% MACs, 1.09 GFLOPS = 2.6183% FLOPs\n",
      "              (norm1): BatchNorm2d(0 = 0% Params, 0 MACs = 0% MACs, 2.1 MFLOPS = 0.0051% FLOPs, 64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "              (fc1): Conv2d(0 = 0% Params, 268.44 MMACs = 1.305% MACs, 541.07 MFLOPS = 1.3053% FLOPs, 64, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "              (act): GELU(0 = 0% Params, 0 MACs = 0% MACs, 4.19 MFLOPS = 0.0101% FLOPs, approximate='none')\n",
      "              (fc2): Conv2d(0 = 0% Params, 268.44 MMACs = 1.305% MACs, 537.92 MFLOPS = 1.2978% FLOPs, 256, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "              (drop): Dropout(0 = 0% Params, 0 MACs = 0% MACs, 0 FLOPS = 0% FLOPs, p=0.0, inplace=False)\n",
      "            )\n",
      "            (drop_path): Identity(0 = 0% Params, 0 MACs = 0% MACs, 0 FLOPS = 0% FLOPs)\n",
      "            (layer_scale_1): LayerScale2d(0 = 0% Params, 0 MACs = 0% MACs, 0 FLOPS = 0% FLOPs)\n",
      "            (layer_scale_2): LayerScale2d(0 = 0% Params, 0 MACs = 0% MACs, 0 FLOPS = 0% FLOPs)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (2): Stage(\n",
      "        0 = 0% Params, 9.47 GMACs = 46.0365% MACs, 19.02 GFLOPS = 45.8829% FLOPs\n",
      "        (downsample): Embedding(\n",
      "          0 = 0% Params, 396.36 MMACs = 1.927% MACs, 794.79 MFLOPS = 1.9175% FLOPs\n",
      "          (proj): Conv2d(0 = 0% Params, 396.36 MMACs = 1.927% MACs, 793.41 MFLOPS = 1.9141% FLOPs, 64, 168, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "          (norm): BatchNorm2d(0 = 0% Params, 0 MACs = 0% MACs, 1.38 MFLOPS = 0.0033% FLOPs, 168, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "        (blocks): Sequential(\n",
      "          0 = 0% Params, 9.07 GMACs = 44.1096% MACs, 18.22 GFLOPS = 43.9654% FLOPs\n",
      "          (0): ConvEncoder(\n",
      "            0 = 0% Params, 931.04 MMACs = 4.5264% MACs, 1.87 GFLOPS = 4.5123% FLOPs\n",
      "            (dwconv): Conv2d(0 = 0% Params, 6.19 MMACs = 0.0301% MACs, 13.07 MFLOPS = 0.0315% FLOPs, 168, 168, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=168)\n",
      "            (norm): BatchNorm2d(0 = 0% Params, 0 MACs = 0% MACs, 1.38 MFLOPS = 0.0033% FLOPs, 168, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (pwconv1): Conv2d(0 = 0% Params, 462.42 MMACs = 2.2481% MACs, 927.6 MFLOPS = 2.2379% FLOPs, 168, 672, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (act): GELU(0 = 0% Params, 0 MACs = 0% MACs, 2.75 MFLOPS = 0.0066% FLOPs, approximate='none')\n",
      "            (pwconv2): Conv2d(0 = 0% Params, 462.42 MMACs = 2.2481% MACs, 925.53 MFLOPS = 2.2329% FLOPs, 672, 168, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (drop_path): Identity(0 = 0% Params, 0 MACs = 0% MACs, 0 FLOPS = 0% FLOPs)\n",
      "            (layer_scale): LayerScale2d(0 = 0% Params, 0 MACs = 0% MACs, 0 FLOPS = 0% FLOPs)\n",
      "          )\n",
      "          (1): ConvEncoder(\n",
      "            0 = 0% Params, 931.04 MMACs = 4.5264% MACs, 1.87 GFLOPS = 4.5123% FLOPs\n",
      "            (dwconv): Conv2d(0 = 0% Params, 6.19 MMACs = 0.0301% MACs, 13.07 MFLOPS = 0.0315% FLOPs, 168, 168, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=168)\n",
      "            (norm): BatchNorm2d(0 = 0% Params, 0 MACs = 0% MACs, 1.38 MFLOPS = 0.0033% FLOPs, 168, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (pwconv1): Conv2d(0 = 0% Params, 462.42 MMACs = 2.2481% MACs, 927.6 MFLOPS = 2.2379% FLOPs, 168, 672, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (act): GELU(0 = 0% Params, 0 MACs = 0% MACs, 2.75 MFLOPS = 0.0066% FLOPs, approximate='none')\n",
      "            (pwconv2): Conv2d(0 = 0% Params, 462.42 MMACs = 2.2481% MACs, 925.53 MFLOPS = 2.2329% FLOPs, 672, 168, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (drop_path): Identity(0 = 0% Params, 0 MACs = 0% MACs, 0 FLOPS = 0% FLOPs)\n",
      "            (layer_scale): LayerScale2d(0 = 0% Params, 0 MACs = 0% MACs, 0 FLOPS = 0% FLOPs)\n",
      "          )\n",
      "          (2): ConvEncoder(\n",
      "            0 = 0% Params, 931.04 MMACs = 4.5264% MACs, 1.87 GFLOPS = 4.5123% FLOPs\n",
      "            (dwconv): Conv2d(0 = 0% Params, 6.19 MMACs = 0.0301% MACs, 13.07 MFLOPS = 0.0315% FLOPs, 168, 168, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=168)\n",
      "            (norm): BatchNorm2d(0 = 0% Params, 0 MACs = 0% MACs, 1.38 MFLOPS = 0.0033% FLOPs, 168, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (pwconv1): Conv2d(0 = 0% Params, 462.42 MMACs = 2.2481% MACs, 927.6 MFLOPS = 2.2379% FLOPs, 168, 672, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (act): GELU(0 = 0% Params, 0 MACs = 0% MACs, 2.75 MFLOPS = 0.0066% FLOPs, approximate='none')\n",
      "            (pwconv2): Conv2d(0 = 0% Params, 462.42 MMACs = 2.2481% MACs, 925.53 MFLOPS = 2.2329% FLOPs, 672, 168, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (drop_path): Identity(0 = 0% Params, 0 MACs = 0% MACs, 0 FLOPS = 0% FLOPs)\n",
      "            (layer_scale): LayerScale2d(0 = 0% Params, 0 MACs = 0% MACs, 0 FLOPS = 0% FLOPs)\n",
      "          )\n",
      "          (3): ConvEncoder(\n",
      "            0 = 0% Params, 931.04 MMACs = 4.5264% MACs, 1.87 GFLOPS = 4.5123% FLOPs\n",
      "            (dwconv): Conv2d(0 = 0% Params, 6.19 MMACs = 0.0301% MACs, 13.07 MFLOPS = 0.0315% FLOPs, 168, 168, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=168)\n",
      "            (norm): BatchNorm2d(0 = 0% Params, 0 MACs = 0% MACs, 1.38 MFLOPS = 0.0033% FLOPs, 168, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (pwconv1): Conv2d(0 = 0% Params, 462.42 MMACs = 2.2481% MACs, 927.6 MFLOPS = 2.2379% FLOPs, 168, 672, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (act): GELU(0 = 0% Params, 0 MACs = 0% MACs, 2.75 MFLOPS = 0.0066% FLOPs, approximate='none')\n",
      "            (pwconv2): Conv2d(0 = 0% Params, 462.42 MMACs = 2.2481% MACs, 925.53 MFLOPS = 2.2329% FLOPs, 672, 168, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (drop_path): Identity(0 = 0% Params, 0 MACs = 0% MACs, 0 FLOPS = 0% FLOPs)\n",
      "            (layer_scale): LayerScale2d(0 = 0% Params, 0 MACs = 0% MACs, 0 FLOPS = 0% FLOPs)\n",
      "          )\n",
      "          (4): ConvEncoder(\n",
      "            0 = 0% Params, 931.04 MMACs = 4.5264% MACs, 1.87 GFLOPS = 4.5123% FLOPs\n",
      "            (dwconv): Conv2d(0 = 0% Params, 6.19 MMACs = 0.0301% MACs, 13.07 MFLOPS = 0.0315% FLOPs, 168, 168, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=168)\n",
      "            (norm): BatchNorm2d(0 = 0% Params, 0 MACs = 0% MACs, 1.38 MFLOPS = 0.0033% FLOPs, 168, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (pwconv1): Conv2d(0 = 0% Params, 462.42 MMACs = 2.2481% MACs, 927.6 MFLOPS = 2.2379% FLOPs, 168, 672, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (act): GELU(0 = 0% Params, 0 MACs = 0% MACs, 2.75 MFLOPS = 0.0066% FLOPs, approximate='none')\n",
      "            (pwconv2): Conv2d(0 = 0% Params, 462.42 MMACs = 2.2481% MACs, 925.53 MFLOPS = 2.2329% FLOPs, 672, 168, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (drop_path): Identity(0 = 0% Params, 0 MACs = 0% MACs, 0 FLOPS = 0% FLOPs)\n",
      "            (layer_scale): LayerScale2d(0 = 0% Params, 0 MACs = 0% MACs, 0 FLOPS = 0% FLOPs)\n",
      "          )\n",
      "          (5): ConvEncoder(\n",
      "            0 = 0% Params, 931.04 MMACs = 4.5264% MACs, 1.87 GFLOPS = 4.5123% FLOPs\n",
      "            (dwconv): Conv2d(0 = 0% Params, 6.19 MMACs = 0.0301% MACs, 13.07 MFLOPS = 0.0315% FLOPs, 168, 168, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=168)\n",
      "            (norm): BatchNorm2d(0 = 0% Params, 0 MACs = 0% MACs, 1.38 MFLOPS = 0.0033% FLOPs, 168, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (pwconv1): Conv2d(0 = 0% Params, 462.42 MMACs = 2.2481% MACs, 927.6 MFLOPS = 2.2379% FLOPs, 168, 672, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (act): GELU(0 = 0% Params, 0 MACs = 0% MACs, 2.75 MFLOPS = 0.0066% FLOPs, approximate='none')\n",
      "            (pwconv2): Conv2d(0 = 0% Params, 462.42 MMACs = 2.2481% MACs, 925.53 MFLOPS = 2.2329% FLOPs, 672, 168, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (drop_path): Identity(0 = 0% Params, 0 MACs = 0% MACs, 0 FLOPS = 0% FLOPs)\n",
      "            (layer_scale): LayerScale2d(0 = 0% Params, 0 MACs = 0% MACs, 0 FLOPS = 0% FLOPs)\n",
      "          )\n",
      "          (6): ConvEncoder(\n",
      "            0 = 0% Params, 931.04 MMACs = 4.5264% MACs, 1.87 GFLOPS = 4.5123% FLOPs\n",
      "            (dwconv): Conv2d(0 = 0% Params, 6.19 MMACs = 0.0301% MACs, 13.07 MFLOPS = 0.0315% FLOPs, 168, 168, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=168)\n",
      "            (norm): BatchNorm2d(0 = 0% Params, 0 MACs = 0% MACs, 1.38 MFLOPS = 0.0033% FLOPs, 168, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (pwconv1): Conv2d(0 = 0% Params, 462.42 MMACs = 2.2481% MACs, 927.6 MFLOPS = 2.2379% FLOPs, 168, 672, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (act): GELU(0 = 0% Params, 0 MACs = 0% MACs, 2.75 MFLOPS = 0.0066% FLOPs, approximate='none')\n",
      "            (pwconv2): Conv2d(0 = 0% Params, 462.42 MMACs = 2.2481% MACs, 925.53 MFLOPS = 2.2329% FLOPs, 672, 168, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (drop_path): Identity(0 = 0% Params, 0 MACs = 0% MACs, 0 FLOPS = 0% FLOPs)\n",
      "            (layer_scale): LayerScale2d(0 = 0% Params, 0 MACs = 0% MACs, 0 FLOPS = 0% FLOPs)\n",
      "          )\n",
      "          (7): ConvEncoder(\n",
      "            0 = 0% Params, 931.04 MMACs = 4.5264% MACs, 1.87 GFLOPS = 4.5123% FLOPs\n",
      "            (dwconv): Conv2d(0 = 0% Params, 6.19 MMACs = 0.0301% MACs, 13.07 MFLOPS = 0.0315% FLOPs, 168, 168, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=168)\n",
      "            (norm): BatchNorm2d(0 = 0% Params, 0 MACs = 0% MACs, 1.38 MFLOPS = 0.0033% FLOPs, 168, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (pwconv1): Conv2d(0 = 0% Params, 462.42 MMACs = 2.2481% MACs, 927.6 MFLOPS = 2.2379% FLOPs, 168, 672, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (act): GELU(0 = 0% Params, 0 MACs = 0% MACs, 2.75 MFLOPS = 0.0066% FLOPs, approximate='none')\n",
      "            (pwconv2): Conv2d(0 = 0% Params, 462.42 MMACs = 2.2481% MACs, 925.53 MFLOPS = 2.2329% FLOPs, 672, 168, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (drop_path): Identity(0 = 0% Params, 0 MACs = 0% MACs, 0 FLOPS = 0% FLOPs)\n",
      "            (layer_scale): LayerScale2d(0 = 0% Params, 0 MACs = 0% MACs, 0 FLOPS = 0% FLOPs)\n",
      "          )\n",
      "          (8): Block(\n",
      "            0 = 0% Params, 1.62 GMACs = 7.8986% MACs, 3.26 GFLOPS = 7.8674% FLOPs\n",
      "            (local_representation): LocalRepresentation(\n",
      "              0 = 0% Params, 237.4 MMACs = 1.1542% MACs, 478.94 MFLOPS = 1.1555% FLOPs\n",
      "              (dwconv): Conv2d(0 = 0% Params, 6.19 MMACs = 0.0301% MACs, 13.07 MFLOPS = 0.0315% FLOPs, 168, 168, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=168)\n",
      "              (norm): BatchNorm2d(0 = 0% Params, 0 MACs = 0% MACs, 1.38 MFLOPS = 0.0033% FLOPs, 168, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "              (pwconv1): Conv2d(0 = 0% Params, 115.61 MMACs = 0.562% MACs, 231.9 MFLOPS = 0.5595% FLOPs, 168, 168, kernel_size=(1, 1), stride=(1, 1))\n",
      "              (act): GELU(0 = 0% Params, 0 MACs = 0% MACs, 688.13 KFLOPS = 0.0017% FLOPs, approximate='none')\n",
      "              (pwconv2): Conv2d(0 = 0% Params, 115.61 MMACs = 0.562% MACs, 231.9 MFLOPS = 0.5595% FLOPs, 168, 168, kernel_size=(1, 1), stride=(1, 1))\n",
      "              (drop_path): Identity(0 = 0% Params, 0 MACs = 0% MACs, 0 FLOPS = 0% FLOPs)\n",
      "              (layer_scale): LayerScale2d(0 = 0% Params, 0 MACs = 0% MACs, 0 FLOPS = 0% FLOPs)\n",
      "            )\n",
      "            (attn): EfficientAdditiveAttention(\n",
      "              0 = 0% Params, 462.42 MMACs = 2.2481% MACs, 924.84 MFLOPS = 2.2312% FLOPs\n",
      "              (to_query): Linear(0 = 0% Params, 115.61 MMACs = 0.562% MACs, 231.21 MFLOPS = 0.5578% FLOPs, in_features=168, out_features=168, bias=True)\n",
      "              (to_key): Linear(0 = 0% Params, 115.61 MMACs = 0.562% MACs, 231.21 MFLOPS = 0.5578% FLOPs, in_features=168, out_features=168, bias=True)\n",
      "              (proj): Linear(0 = 0% Params, 115.61 MMACs = 0.562% MACs, 231.21 MFLOPS = 0.5578% FLOPs, in_features=168, out_features=168, bias=True)\n",
      "              (final): Linear(0 = 0% Params, 115.61 MMACs = 0.562% MACs, 231.21 MFLOPS = 0.5578% FLOPs, in_features=168, out_features=168, bias=True)\n",
      "            )\n",
      "            (linear): Mlp(\n",
      "              0 = 0% Params, 924.84 MMACs = 4.4963% MACs, 1.86 GFLOPS = 4.4807% FLOPs\n",
      "              (norm1): BatchNorm2d(0 = 0% Params, 0 MACs = 0% MACs, 1.38 MFLOPS = 0.0033% FLOPs, 168, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "              (fc1): Conv2d(0 = 0% Params, 462.42 MMACs = 2.2481% MACs, 927.6 MFLOPS = 2.2379% FLOPs, 168, 672, kernel_size=(1, 1), stride=(1, 1))\n",
      "              (act): GELU(0 = 0% Params, 0 MACs = 0% MACs, 2.75 MFLOPS = 0.0066% FLOPs, approximate='none')\n",
      "              (fc2): Conv2d(0 = 0% Params, 462.42 MMACs = 2.2481% MACs, 925.53 MFLOPS = 2.2329% FLOPs, 672, 168, kernel_size=(1, 1), stride=(1, 1))\n",
      "              (drop): Dropout(0 = 0% Params, 0 MACs = 0% MACs, 0 FLOPS = 0% FLOPs, p=0.0, inplace=False)\n",
      "            )\n",
      "            (drop_path): Identity(0 = 0% Params, 0 MACs = 0% MACs, 0 FLOPS = 0% FLOPs)\n",
      "            (layer_scale_1): LayerScale2d(0 = 0% Params, 0 MACs = 0% MACs, 0 FLOPS = 0% FLOPs)\n",
      "            (layer_scale_2): LayerScale2d(0 = 0% Params, 0 MACs = 0% MACs, 0 FLOPS = 0% FLOPs)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (3): Stage(\n",
      "        0 = 0% Params, 3.13 GMACs = 15.2351% MACs, 6.29 GFLOPS = 15.1648% FLOPs\n",
      "        (downsample): Embedding(\n",
      "          0 = 0% Params, 346.82 MMACs = 1.6861% MACs, 694.32 MFLOPS = 1.6751% FLOPs\n",
      "          (proj): Conv2d(0 = 0% Params, 346.82 MMACs = 1.6861% MACs, 693.86 MFLOPS = 1.674% FLOPs, 168, 224, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "          (norm): BatchNorm2d(0 = 0% Params, 0 MACs = 0% MACs, 458.75 KFLOPS = 0.0011% FLOPs, 224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "        (blocks): Sequential(\n",
      "          0 = 0% Params, 2.79 GMACs = 13.549% MACs, 5.59 GFLOPS = 13.4897% FLOPs\n",
      "          (0): ConvEncoder(\n",
      "            0 = 0% Params, 413.11 MMACs = 2.0084% MACs, 828.96 MFLOPS = 1.9999% FLOPs\n",
      "            (dwconv): Conv2d(0 = 0% Params, 2.06 MMACs = 0.01% MACs, 4.36 MFLOPS = 0.0105% FLOPs, 224, 224, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=224)\n",
      "            (norm): BatchNorm2d(0 = 0% Params, 0 MACs = 0% MACs, 458.75 KFLOPS = 0.0011% FLOPs, 224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (pwconv1): Conv2d(0 = 0% Params, 205.52 MMACs = 0.9992% MACs, 411.96 MFLOPS = 0.9939% FLOPs, 224, 896, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (act): GELU(0 = 0% Params, 0 MACs = 0% MACs, 917.5 KFLOPS = 0.0022% FLOPs, approximate='none')\n",
      "            (pwconv2): Conv2d(0 = 0% Params, 205.52 MMACs = 0.9992% MACs, 411.27 MFLOPS = 0.9922% FLOPs, 896, 224, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (drop_path): Identity(0 = 0% Params, 0 MACs = 0% MACs, 0 FLOPS = 0% FLOPs)\n",
      "            (layer_scale): LayerScale2d(0 = 0% Params, 0 MACs = 0% MACs, 0 FLOPS = 0% FLOPs)\n",
      "          )\n",
      "          (1): ConvEncoder(\n",
      "            0 = 0% Params, 413.11 MMACs = 2.0084% MACs, 828.96 MFLOPS = 1.9999% FLOPs\n",
      "            (dwconv): Conv2d(0 = 0% Params, 2.06 MMACs = 0.01% MACs, 4.36 MFLOPS = 0.0105% FLOPs, 224, 224, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=224)\n",
      "            (norm): BatchNorm2d(0 = 0% Params, 0 MACs = 0% MACs, 458.75 KFLOPS = 0.0011% FLOPs, 224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (pwconv1): Conv2d(0 = 0% Params, 205.52 MMACs = 0.9992% MACs, 411.96 MFLOPS = 0.9939% FLOPs, 224, 896, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (act): GELU(0 = 0% Params, 0 MACs = 0% MACs, 917.5 KFLOPS = 0.0022% FLOPs, approximate='none')\n",
      "            (pwconv2): Conv2d(0 = 0% Params, 205.52 MMACs = 0.9992% MACs, 411.27 MFLOPS = 0.9922% FLOPs, 896, 224, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (drop_path): Identity(0 = 0% Params, 0 MACs = 0% MACs, 0 FLOPS = 0% FLOPs)\n",
      "            (layer_scale): LayerScale2d(0 = 0% Params, 0 MACs = 0% MACs, 0 FLOPS = 0% FLOPs)\n",
      "          )\n",
      "          (2): ConvEncoder(\n",
      "            0 = 0% Params, 413.11 MMACs = 2.0084% MACs, 828.96 MFLOPS = 1.9999% FLOPs\n",
      "            (dwconv): Conv2d(0 = 0% Params, 2.06 MMACs = 0.01% MACs, 4.36 MFLOPS = 0.0105% FLOPs, 224, 224, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=224)\n",
      "            (norm): BatchNorm2d(0 = 0% Params, 0 MACs = 0% MACs, 458.75 KFLOPS = 0.0011% FLOPs, 224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (pwconv1): Conv2d(0 = 0% Params, 205.52 MMACs = 0.9992% MACs, 411.96 MFLOPS = 0.9939% FLOPs, 224, 896, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (act): GELU(0 = 0% Params, 0 MACs = 0% MACs, 917.5 KFLOPS = 0.0022% FLOPs, approximate='none')\n",
      "            (pwconv2): Conv2d(0 = 0% Params, 205.52 MMACs = 0.9992% MACs, 411.27 MFLOPS = 0.9922% FLOPs, 896, 224, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (drop_path): Identity(0 = 0% Params, 0 MACs = 0% MACs, 0 FLOPS = 0% FLOPs)\n",
      "            (layer_scale): LayerScale2d(0 = 0% Params, 0 MACs = 0% MACs, 0 FLOPS = 0% FLOPs)\n",
      "          )\n",
      "          (3): ConvEncoder(\n",
      "            0 = 0% Params, 413.11 MMACs = 2.0084% MACs, 828.96 MFLOPS = 1.9999% FLOPs\n",
      "            (dwconv): Conv2d(0 = 0% Params, 2.06 MMACs = 0.01% MACs, 4.36 MFLOPS = 0.0105% FLOPs, 224, 224, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=224)\n",
      "            (norm): BatchNorm2d(0 = 0% Params, 0 MACs = 0% MACs, 458.75 KFLOPS = 0.0011% FLOPs, 224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (pwconv1): Conv2d(0 = 0% Params, 205.52 MMACs = 0.9992% MACs, 411.96 MFLOPS = 0.9939% FLOPs, 224, 896, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (act): GELU(0 = 0% Params, 0 MACs = 0% MACs, 917.5 KFLOPS = 0.0022% FLOPs, approximate='none')\n",
      "            (pwconv2): Conv2d(0 = 0% Params, 205.52 MMACs = 0.9992% MACs, 411.27 MFLOPS = 0.9922% FLOPs, 896, 224, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (drop_path): Identity(0 = 0% Params, 0 MACs = 0% MACs, 0 FLOPS = 0% FLOPs)\n",
      "            (layer_scale): LayerScale2d(0 = 0% Params, 0 MACs = 0% MACs, 0 FLOPS = 0% FLOPs)\n",
      "          )\n",
      "          (4): ConvEncoder(\n",
      "            0 = 0% Params, 413.11 MMACs = 2.0084% MACs, 828.96 MFLOPS = 1.9999% FLOPs\n",
      "            (dwconv): Conv2d(0 = 0% Params, 2.06 MMACs = 0.01% MACs, 4.36 MFLOPS = 0.0105% FLOPs, 224, 224, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=224)\n",
      "            (norm): BatchNorm2d(0 = 0% Params, 0 MACs = 0% MACs, 458.75 KFLOPS = 0.0011% FLOPs, 224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (pwconv1): Conv2d(0 = 0% Params, 205.52 MMACs = 0.9992% MACs, 411.96 MFLOPS = 0.9939% FLOPs, 224, 896, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (act): GELU(0 = 0% Params, 0 MACs = 0% MACs, 917.5 KFLOPS = 0.0022% FLOPs, approximate='none')\n",
      "            (pwconv2): Conv2d(0 = 0% Params, 205.52 MMACs = 0.9992% MACs, 411.27 MFLOPS = 0.9922% FLOPs, 896, 224, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (drop_path): Identity(0 = 0% Params, 0 MACs = 0% MACs, 0 FLOPS = 0% FLOPs)\n",
      "            (layer_scale): LayerScale2d(0 = 0% Params, 0 MACs = 0% MACs, 0 FLOPS = 0% FLOPs)\n",
      "          )\n",
      "          (5): Block(\n",
      "            0 = 0% Params, 721.39 MMACs = 3.5071% MACs, 1.45 GFLOPS = 3.4902% FLOPs\n",
      "            (local_representation): LocalRepresentation(\n",
      "              0 = 0% Params, 104.82 MMACs = 0.5096% MACs, 211.03 MFLOPS = 0.5091% FLOPs\n",
      "              (dwconv): Conv2d(0 = 0% Params, 2.06 MMACs = 0.01% MACs, 4.36 MFLOPS = 0.0105% FLOPs, 224, 224, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=224)\n",
      "              (norm): BatchNorm2d(0 = 0% Params, 0 MACs = 0% MACs, 458.75 KFLOPS = 0.0011% FLOPs, 224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "              (pwconv1): Conv2d(0 = 0% Params, 51.38 MMACs = 0.2498% MACs, 102.99 MFLOPS = 0.2485% FLOPs, 224, 224, kernel_size=(1, 1), stride=(1, 1))\n",
      "              (act): GELU(0 = 0% Params, 0 MACs = 0% MACs, 229.38 KFLOPS = 0.0006% FLOPs, approximate='none')\n",
      "              (pwconv2): Conv2d(0 = 0% Params, 51.38 MMACs = 0.2498% MACs, 102.99 MFLOPS = 0.2485% FLOPs, 224, 224, kernel_size=(1, 1), stride=(1, 1))\n",
      "              (drop_path): Identity(0 = 0% Params, 0 MACs = 0% MACs, 0 FLOPS = 0% FLOPs)\n",
      "              (layer_scale): LayerScale2d(0 = 0% Params, 0 MACs = 0% MACs, 0 FLOPS = 0% FLOPs)\n",
      "            )\n",
      "            (attn): EfficientAdditiveAttention(\n",
      "              0 = 0% Params, 205.52 MMACs = 0.9992% MACs, 411.04 MFLOPS = 0.9917% FLOPs\n",
      "              (to_query): Linear(0 = 0% Params, 51.38 MMACs = 0.2498% MACs, 102.76 MFLOPS = 0.2479% FLOPs, in_features=224, out_features=224, bias=True)\n",
      "              (to_key): Linear(0 = 0% Params, 51.38 MMACs = 0.2498% MACs, 102.76 MFLOPS = 0.2479% FLOPs, in_features=224, out_features=224, bias=True)\n",
      "              (proj): Linear(0 = 0% Params, 51.38 MMACs = 0.2498% MACs, 102.76 MFLOPS = 0.2479% FLOPs, in_features=224, out_features=224, bias=True)\n",
      "              (final): Linear(0 = 0% Params, 51.38 MMACs = 0.2498% MACs, 102.76 MFLOPS = 0.2479% FLOPs, in_features=224, out_features=224, bias=True)\n",
      "            )\n",
      "            (linear): Mlp(\n",
      "              0 = 0% Params, 411.04 MMACs = 1.9983% MACs, 824.61 MFLOPS = 1.9894% FLOPs\n",
      "              (norm1): BatchNorm2d(0 = 0% Params, 0 MACs = 0% MACs, 458.75 KFLOPS = 0.0011% FLOPs, 224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "              (fc1): Conv2d(0 = 0% Params, 205.52 MMACs = 0.9992% MACs, 411.96 MFLOPS = 0.9939% FLOPs, 224, 896, kernel_size=(1, 1), stride=(1, 1))\n",
      "              (act): GELU(0 = 0% Params, 0 MACs = 0% MACs, 917.5 KFLOPS = 0.0022% FLOPs, approximate='none')\n",
      "              (fc2): Conv2d(0 = 0% Params, 205.52 MMACs = 0.9992% MACs, 411.27 MFLOPS = 0.9922% FLOPs, 896, 224, kernel_size=(1, 1), stride=(1, 1))\n",
      "              (drop): Dropout(0 = 0% Params, 0 MACs = 0% MACs, 0 FLOPS = 0% FLOPs, p=0.0, inplace=False)\n",
      "            )\n",
      "            (drop_path): Identity(0 = 0% Params, 0 MACs = 0% MACs, 0 FLOPS = 0% FLOPs)\n",
      "            (layer_scale_1): LayerScale2d(0 = 0% Params, 0 MACs = 0% MACs, 0 FLOPS = 0% FLOPs)\n",
      "            (layer_scale_2): LayerScale2d(0 = 0% Params, 0 MACs = 0% MACs, 0 FLOPS = 0% FLOPs)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (norm): BatchNorm2d(0 = 0% Params, 0 MACs = 0% MACs, 458.75 KFLOPS = 0.0011% FLOPs, 224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (head_drop): Dropout(0 = 0% Params, 0 MACs = 0% MACs, 0 FLOPS = 0% FLOPs, p=0.0, inplace=False)\n",
      "    (head): Identity(0 = 0% Params, 0 MACs = 0% MACs, 0 FLOPS = 0% FLOPs)\n",
      "    (head_dist): Identity(0 = 0% Params, 0 MACs = 0% MACs, 0 FLOPS = 0% FLOPs)\n",
      "  )\n",
      "  (head): MLP(\n",
      "    116.23 K = 100% Params, 7.41 MMACs = 0.036% MACs, 15.07 MFLOPS = 0.0364% FLOPs\n",
      "    (model): Sequential(\n",
      "      116.23 K = 100% Params, 7.41 MMACs = 0.036% MACs, 15.07 MFLOPS = 0.0364% FLOPs\n",
      "      (0): AdaptiveAvgPool2d(0 = 0% Params, 0 MACs = 0% MACs, 229.38 KFLOPS = 0.0006% FLOPs, output_size=(1, 1))\n",
      "      (1): Flatten(0 = 0% Params, 0 MACs = 0% MACs, 0 FLOPS = 0% FLOPs, start_dim=1, end_dim=-1)\n",
      "      (2): Linear(115.2 K = 99.1172% Params, 7.34 MMACs = 0.0357% MACs, 14.68 MFLOPS = 0.0354% FLOPs, in_features=224, out_features=512, bias=True)\n",
      "      (3): ReLU(0 = 0% Params, 0 MACs = 0% MACs, 32.77 KFLOPS = 0.0001% FLOPs)\n",
      "      (4): Dropout(0 = 0% Params, 0 MACs = 0% MACs, 0 FLOPS = 0% FLOPs, p=0.5, inplace=False)\n",
      "      (5): Linear(1.03 K = 0.8828% Params, 65.54 KMACs = 0.0003% MACs, 131.07 KFLOPS = 0.0003% FLOPs, in_features=512, out_features=2, bias=True)\n",
      "    )\n",
      "  )\n",
      ")\n",
      "---------------------------------------------------------------------------------------------------\n",
      "\n",
      "METRICS =================================\n",
      "Accuracy: 77.42%\n",
      "Precision: 1.0000\n",
      "Recall: 0.7742\n",
      "F1-Score: 0.8727\n",
      "\n",
      "EFFICIENCY ==============================\n",
      "FLOPs: 41.4501 GFLOPS\n",
      "MACs: 20.5692 GMACs\n",
      "Params: 116.226 K\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "CLASS_NAMES = ['real', 'fake']\n",
    "metrics, cm = test(dm)\n",
    "\n",
    "plt.figure(figsize=(6, 6))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=CLASS_NAMES, yticklabels=CLASS_NAMES)\n",
    "plt.title('Confusion Matrix')\n",
    "plt.ylabel('True Label')\n",
    "plt.xlabel('Predicted Label')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dd58411",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected real image\n",
      "Confidence score: 99.6666%\n"
     ]
    }
   ],
   "source": [
    "cat, confidence, _ = predict_single_img('test_imgs/test_ai.jpg')\n",
    "print(f\"Detected {CLASS_NAMES[cat]} image\")\n",
    "print(f\"Confidence score: {100 * confidence:.4f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1466042c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "imageclassification",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
